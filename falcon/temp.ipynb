{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path : /home/nlpshlee/dev_env/git/repos/memit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PATH = os.path.abspath('..')\n",
    "print(f\"path : {PATH}\")\n",
    "\n",
    "# 최상위 경로 저장\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from typing import Tuple, Union, List\n",
    "from itertools import chain\n",
    "from time import time\n",
    "\n",
    "from falcon.falcon_util import *\n",
    "from util.globals import *\n",
    "from util import nethook\n",
    "\n",
    "from baselines.ft import FTHyperParams, apply_ft_to_model\n",
    "from baselines.mend import MENDHyperParams, MendRewriteExecutor\n",
    "from rome import ROMEHyperParams, apply_rome_to_model\n",
    "from memit import MEMITHyperParams, apply_memit_to_model\n",
    "\n",
    "from experiments.py.eval_utils_counterfact import compute_rewrite_quality_counterfact, test_batch_prediction, test_generation\n",
    "from experiments.py.eval_utils_zsre import compute_rewrite_quality_zsre\n",
    "\n",
    "\n",
    "from dsets import (\n",
    "    AttributeSnippets,\n",
    "    CounterFactDataset,\n",
    "    MENDQADataset,\n",
    "    MultiCounterFactDataset,\n",
    "    get_tfidf_vectorizer\n",
    ")\n",
    "\n",
    "ALG_DICT = {\n",
    "    'FT': (FTHyperParams, apply_ft_to_model),\n",
    "    'MEND': (MENDHyperParams, MendRewriteExecutor().apply_to_model),\n",
    "    'ROME': (ROMEHyperParams, apply_rome_to_model),\n",
    "    'MEMIT': (MEMITHyperParams, apply_memit_to_model)\n",
    "}\n",
    "\n",
    "\n",
    "DS_DICT = {\n",
    "    'mcf': (MultiCounterFactDataset, compute_rewrite_quality_counterfact),\n",
    "    'cf': (CounterFactDataset, compute_rewrite_quality_counterfact),\n",
    "    'zsre': (MENDQADataset, compute_rewrite_quality_zsre),\n",
    "}\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model_name):\n",
    "    if type(model_name) is str:\n",
    "        print('# init_model() Instantiating model')\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "        tok = AutoTokenizer.from_pretrained(model_name)\n",
    "        tok.pad_token = tok.eos_token\n",
    "    else:\n",
    "        model, tok = model_name\n",
    "        model_name = model.config._name_or_path\n",
    "    print(f'\\tmodel : {type(model)}')\n",
    "    print(f'\\ttokenizer : {type(tok)}\\n')\n",
    "\n",
    "    return model, tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ds_name, tok, dataset_size_limit):\n",
    "    ds_class, ds_eval_method = DS_DICT[ds_name]\n",
    "    print(f'# data_load() ds_class : {ds_class}')\n",
    "    print(f'# data_load() ds_eval_method : {ds_eval_method}\\n')\n",
    "    ds = ds_class(DATA_DIR, tok=tok, size=dataset_size_limit)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# init_model() Instantiating model\n",
      "\tmodel : <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "\ttokenizer : <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2-xl'\n",
    "model, tok = init_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data_load() ds_class : <class 'dsets.counterfact.MultiCounterFactDataset'>\n",
      "# data_load() ds_eval_method : <function compute_rewrite_quality_counterfact at 0x7fb84f2713a0>\n",
      "\n",
      "Loaded dataset with 20877 elements\n"
     ]
    }
   ],
   "source": [
    "ds_name = 'mcf'\n",
    "dataset_size_limit = None\n",
    "ds = load_data(ds_name, tok, dataset_size_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tok, prompts: List[str], top_k, max_out_len):\n",
    "    outputs = model.generate(**tok(prompts, return_tensors='pt').to('cuda'),\n",
    "                             top_k=top_k, max_length=max_out_len,\n",
    "                             do_sample=False, num_beams=1,\n",
    "                             pad_token_id=tok.eos_token_id\n",
    "    )\n",
    "    \n",
    "    return str(tok.decode(outputs[0], skip_special_token=True)).replace('\\n', '\\t').replace('[\\t]+', '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "record_dict = {}\n",
    "\n",
    "for record in ds:\n",
    "    case_id = record['case_id']\n",
    "    prompt, subject, target_new, target_true = (\n",
    "        record['requested_rewrite'][x] for x in ['prompt', 'subject', 'target_new', 'target_true']\n",
    "    )\n",
    "\n",
    "    prompt_with_subject = prompt.format(subject)\n",
    "    target_new = target_new['str']\n",
    "    target_true = target_true['str']\n",
    "\n",
    "    value = {'case_id': case_id, 'prompt': prompt_with_subject, 'target_new': target_new, 'target_true': target_true}\n",
    "\n",
    "    if not subject in record_dict.keys():\n",
    "        record_dict[subject] = [value]\n",
    "    else:\n",
    "        record_dict[subject].append(value)\n",
    "\n",
    "with open('./searched_multi_subject.txt', 'w') as f:\n",
    "    for subject, values in record_dict.items():\n",
    "        value_len = len(values)\n",
    "        if value_len > 1:\n",
    "            \n",
    "            _checked = True\n",
    "            for idx, value in enumerate(values):\n",
    "                case_id, prompt, target_true, target_new = value['case_id'], value['prompt'], value['target_true'], value['target_new']\n",
    "                org_texts = f'{prompt} {target_true}'\n",
    "                gen_texts = generate(model, tok, [prompt], 1, 100)\n",
    "\n",
    "                if not gen_texts.startswith(org_texts):\n",
    "                    _checked = False\n",
    "                    break\n",
    "            \n",
    "            if _checked:\n",
    "                f.write(f'### Subject : {subject}, value_len : {value_len}\\n\\n')\n",
    "\n",
    "                for idx, value in enumerate(values):\n",
    "                    case_id, prompt, target_true, target_new = value['case_id'], value['prompt'], value['target_true'], value['target_new']\n",
    "                    org_texts = f'{prompt} {target_true}'\n",
    "                    gen_texts = generate(model, tok, [prompt], 1, 100)\n",
    "\n",
    "                    f.write(f'[{idx}] case_id : {case_id}, prompt : {prompt}\\n')\n",
    "                    f.write(f'[{idx}] target_true : {target_true}\\n')\n",
    "                    f.write(f'[{idx}] target_new : {target_new}\\n\\n')\n",
    "                    f.write(f'[{idx}] org_texts : {org_texts}\\n')\n",
    "                    f.write(f'[{idx}] gen_texts : {gen_texts}\\n\\n')\n",
    "                    f.flush()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    key를 기준으로 정렬\n",
    "        - is_reverse = False : 오름 차순\n",
    "        - is_reverse = True : 내림 차순\n",
    "'''\n",
    "def sorted_dict_key(in_dict: dict, is_reverse=False) :\n",
    "    return dict(sorted(in_dict.items(), key=lambda item:item[0], reverse=is_reverse))\n",
    "\n",
    "'''\n",
    "    value를 기준으로 정렬\n",
    "        - is_reverse = False : 오름 차순\n",
    "        - is_reverse = True : 내림 차순\n",
    "'''\n",
    "def sorted_dict_value(in_dict: dict, is_reverse=False) :\n",
    "    return dict(sorted(in_dict.items(), key=lambda item:item[1], reverse=is_reverse))\n",
    "\n",
    "'''\n",
    "    key를 기준으로 오름 차순 정렬, value를 기준으로 내림 차순 정렬\n",
    "'''\n",
    "def sorted_dict(in_dict: dict):\n",
    "    return sorted_dict_value(sorted_dict_key(in_dict, False), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_edge_symbols(text: str, symbols='!.,?-\\'\"'):\n",
    "    return text.strip(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def _post(text: str):\n",
    "    return re.sub(r'[\\t\\n ]+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_dict_freq(in_dict: dict, key: str, value=1):\n",
    "    if key in in_dict.keys():\n",
    "        in_dict[key] += value\n",
    "    else:\n",
    "        in_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_sorted(in_dict: dict, out_file_path: str):\n",
    "    _sorted_dict = sorted_dict(in_dict)\n",
    "\n",
    "    with open(out_file_path, 'w') as f:\n",
    "        for key, value in _sorted_dict.items():\n",
    "            f.write(f'{key}\\t{value}\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_substrings(text):\n",
    "    # 어절 단위로 문자열 분리\n",
    "    words = text.split()\n",
    "\n",
    "    # 가능한 모든 부분 문자열 리스트 생성\n",
    "    temp = []\n",
    "    for start in range(len(words)):\n",
    "        for end in range(start + 1, len(words) + 1):\n",
    "            temp.append(' '.join(words[start:end]))\n",
    "    \n",
    "    substrs = []\n",
    "    for substr in temp:\n",
    "        substr = substr.replace('{}', '')\n",
    "        substr = remove_edge_symbols(substr)\n",
    "\n",
    "        if substr[:2] == 's ':\n",
    "            substr = substr[2:]\n",
    "        \n",
    "        substr = _post(substr)\n",
    "        \n",
    "        if len(substr) > 0:\n",
    "            substrs.append(substr)\n",
    "\n",
    "    return substrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "check_dict = {}\n",
    "\n",
    "for record in ds:\n",
    "    case_id = record['case_id']\n",
    "    prompt, subject, target_new, target_true = (\n",
    "        record['requested_rewrite'][x] for x in ['prompt', 'subject', 'target_new', 'target_true']\n",
    "    )\n",
    "\n",
    "    substrs = get_all_substrings(prompt)\n",
    "\n",
    "    for substr in substrs:\n",
    "        substr = substr.lower()\n",
    "\n",
    "        _add_dict_freq(check_dict, substr)\n",
    "\n",
    "sorted_check_dict = sorted_dict(check_dict)\n",
    "\n",
    "with open('./searched_multi_substrings_from_prompt.txt', 'w') as f:\n",
    "    for key, value in sorted_check_dict.items():\n",
    "        key_len = len(key.split())\n",
    "        f.write(f'{key_len}\\t{key}\\t{value}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "relation_dict = {}\n",
    "cnt, cnt_relation_front, cnt_relation_mid, cnt_relation_last = 0, 0, 0, 0\n",
    "\n",
    "for record in ds:\n",
    "    case_id = record['case_id']\n",
    "    prompt, subject, target_new, target_true = (\n",
    "        record['requested_rewrite'][x] for x in ['prompt', 'subject', 'target_new', 'target_true']\n",
    "    )\n",
    "\n",
    "    cnt += 1\n",
    "    if prompt[:2] == '{}':\n",
    "        cnt_relation_front += 1\n",
    "\n",
    "        relation = remove_edge_symbols(prompt[2:])\n",
    "        relation = _post(relation)\n",
    "\n",
    "        _add_dict_freq(relation_dict, relation)\n",
    "    elif prompt[-2:] == '{}':\n",
    "        cnt_relation_last += 1\n",
    "    else:\n",
    "        cnt_relation_mid += 1\n",
    "\n",
    "print(f'cnt : {cnt}')\n",
    "print(f'cnt_relation_front : {cnt_relation_front}')\n",
    "print(f'cnt_relation_mid : {cnt_relation_mid}')\n",
    "print(f'cnt_relation_last : {cnt_relation_last}')\n",
    "\n",
    "_write_sorted(relation_dict, './searched_multi_relation_freq.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_known(ent: dict):\n",
    "    known_id = ent['known_id']\n",
    "    subject = ent['subject']\n",
    "    attribute = ent['attribute']\n",
    "    template = ent['template']\n",
    "    prediction = ent['prediction']\n",
    "    prompt = ent['prompt']\n",
    "    relation_id = ent['relation_id']\n",
    "\n",
    "    print(f'known_id : {known_id}')\n",
    "    print(f'subject : {subject}')\n",
    "    print(f'attribute : {attribute}')\n",
    "    print(f'template : {template}')\n",
    "    print(f'prediction : {prediction}')\n",
    "    print(f'prompt : {prompt}')\n",
    "    print(f'relation_id : {relation_id}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "in_file_path = '../data/known_1000.json'\n",
    "out_file_path = '../data/known_1000_sr_switch.json'\n",
    "\n",
    "json_dict_list = json_file_to_dict(in_file_path)\n",
    "write_dict_list = []\n",
    "\n",
    "for ent in json_dict_list:\n",
    "    # _print_known(ent)\n",
    "\n",
    "    template = ent['template']\n",
    "    if template[:2] == '{}':\n",
    "        relation = remove_edge_symbols(template[2:])\n",
    "        relation = _post(relation)\n",
    "\n",
    "        subject = ent['subject']\n",
    "        ent['template'] = subject + ' {}'\n",
    "        ent['subject'] = relation\n",
    "        # _print_known(ent)\n",
    "\n",
    "        write_dict_list.append(ent)\n",
    "\n",
    "print(len(write_dict_list))\n",
    "\n",
    "f = open_file(out_file_path, mode='w')\n",
    "f.write(to_json_str(write_dict_list))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
