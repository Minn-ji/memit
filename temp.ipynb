{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# PATH = os.path.abspath('..')\n",
    "# print(f\"path : {PATH}\")\n",
    "\n",
    "# # 최상위 경로 저장\n",
    "# sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from typing import Tuple, Union, List\n",
    "from itertools import chain\n",
    "from time import time\n",
    "\n",
    "from falcon.falcon_util import *\n",
    "from util.globals import *\n",
    "from util import nethook\n",
    "\n",
    "from baselines.ft import FTHyperParams, apply_ft_to_model\n",
    "from baselines.mend import MENDHyperParams, MendRewriteExecutor\n",
    "from rome import ROMEHyperParams, apply_rome_to_model\n",
    "from memit import MEMITHyperParams, apply_memit_to_model\n",
    "\n",
    "from experiments.py.eval_utils_counterfact import compute_rewrite_quality_counterfact, test_batch_prediction, test_generation\n",
    "from experiments.py.eval_utils_zsre import compute_rewrite_quality_zsre\n",
    "\n",
    "\n",
    "from dsets import (\n",
    "    AttributeSnippets,\n",
    "    CounterFactDataset,\n",
    "    MENDQADataset,\n",
    "    MultiCounterFactDataset,\n",
    "    get_tfidf_vectorizer\n",
    ")\n",
    "\n",
    "ALG_DICT = {\n",
    "    'FT': (FTHyperParams, apply_ft_to_model),\n",
    "    'MEND': (MENDHyperParams, MendRewriteExecutor().apply_to_model),\n",
    "    'ROME': (ROMEHyperParams, apply_rome_to_model),\n",
    "    'MEMIT': (MEMITHyperParams, apply_memit_to_model)\n",
    "}\n",
    "\n",
    "\n",
    "DS_DICT = {\n",
    "    'mcf': (MultiCounterFactDataset, compute_rewrite_quality_counterfact),\n",
    "    'cf': (CounterFactDataset, compute_rewrite_quality_counterfact),\n",
    "    'zsre': (MENDQADataset, compute_rewrite_quality_zsre),\n",
    "}\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model_name):\n",
    "    if type(model_name) is str:\n",
    "        print('# init_model() Instantiating model')\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "        tok = AutoTokenizer.from_pretrained(model_name)\n",
    "        tok.pad_token = tok.eos_token\n",
    "    else:\n",
    "        model, tok = model_name\n",
    "        model_name = model.config._name_or_path\n",
    "    print(f'\\tmodel : {type(model)}')\n",
    "    print(f'\\ttokenizer : {type(tok)}\\n')\n",
    "\n",
    "    return model, tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ds_name, tok, dataset_size_limit):\n",
    "    ds_class, ds_eval_method = DS_DICT[ds_name]\n",
    "    print(f'# data_load() ds_class : {ds_class}')\n",
    "    print(f'# data_load() ds_eval_method : {ds_eval_method}\\n')\n",
    "    ds = ds_class(DATA_DIR, tok=tok, size=dataset_size_limit)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2-xl'\n",
    "model, tok = init_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'mcf'\n",
    "dataset_size_limit = None\n",
    "ds = load_data(ds_name, tok, dataset_size_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tok, prompts: List[str], top_k, max_out_len):\n",
    "    outputs = model.generate(**tok(prompts, return_tensors='pt').to('cuda'),\n",
    "                             top_k=top_k, max_length=max_out_len,\n",
    "                             do_sample=False, num_beams=1,\n",
    "                             pad_token_id=tok.eos_token_id\n",
    "    )\n",
    "    \n",
    "    return str(tok.decode(outputs[0], skip_special_token=True)).replace('\\n', '\\t').replace('[\\t]+', '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    key를 기준으로 정렬\n",
    "        - is_reverse = False : 오름 차순\n",
    "        - is_reverse = True : 내림 차순\n",
    "'''\n",
    "def sorted_dict_key(in_dict: dict, is_reverse=False) :\n",
    "    return dict(sorted(in_dict.items(), key=lambda item:item[0], reverse=is_reverse))\n",
    "\n",
    "'''\n",
    "    value를 기준으로 정렬\n",
    "        - is_reverse = False : 오름 차순\n",
    "        - is_reverse = True : 내림 차순\n",
    "'''\n",
    "def sorted_dict_value(in_dict: dict, is_reverse=False) :\n",
    "    return dict(sorted(in_dict.items(), key=lambda item:item[1], reverse=is_reverse))\n",
    "\n",
    "'''\n",
    "    key를 기준으로 오름 차순 정렬, value를 기준으로 내림 차순 정렬\n",
    "'''\n",
    "def sorted_dict(in_dict: dict):\n",
    "    return sorted_dict_value(sorted_dict_key(in_dict, False), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_edge_symbols(text: str, symbols='!.,?-\\'\"'):\n",
    "    return text.strip(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def _post(text: str):\n",
    "    return re.sub(r'[\\t\\n ]+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_dict_freq(in_dict: dict, key: str, value=1):\n",
    "    if key in in_dict.keys():\n",
    "        in_dict[key] += value\n",
    "    else:\n",
    "        in_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_sorted(in_dict: dict, out_file_path: str):\n",
    "    _sorted_dict = sorted_dict(in_dict)\n",
    "\n",
    "    with open(out_file_path, 'w') as f:\n",
    "        for key, value in _sorted_dict.items():\n",
    "            f.write(f'{key}\\t{value}\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_all_substrings(text):\n",
    "    # 어절 단위로 문자열 분리\n",
    "    words = text.split()\n",
    "\n",
    "    # 가능한 모든 부분 문자열 리스트 생성\n",
    "    temp = []\n",
    "    for start in range(len(words)):\n",
    "        for end in range(start + 1, len(words) + 1):\n",
    "            temp.append(' '.join(words[start:end]))\n",
    "    \n",
    "    substrs = []\n",
    "    for substr in temp:\n",
    "        substr = substr.replace('{}', '')\n",
    "        substr = _remove_edge_symbols(substr)\n",
    "\n",
    "        if substr[:2] == 's ':\n",
    "            substr = substr[2:]\n",
    "        \n",
    "        substr = _post(substr)\n",
    "        \n",
    "        if len(substr) > 0:\n",
    "            substrs.append(substr)\n",
    "\n",
    "    return substrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_known(ent: dict):\n",
    "    known_id = ent['known_id']\n",
    "    subject = ent['subject']\n",
    "    attribute = ent['attribute']\n",
    "    template = ent['template']\n",
    "    prediction = ent['prediction']\n",
    "    prompt = ent['prompt']\n",
    "    relation_id = ent['relation_id']\n",
    "\n",
    "    print(f'known_id : {known_id}')\n",
    "    print(f'subject : {subject}')\n",
    "    print(f'attribute : {attribute}')\n",
    "    print(f'template : {template}')\n",
    "    print(f'prediction : {prediction}')\n",
    "    print(f'prompt : {prompt}')\n",
    "    print(f'relation_id : {relation_id}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _swap_sr(prompt: str, subject: str):\n",
    "    def _refine(text: str):\n",
    "        text = _remove_edge_symbols(text)\n",
    "        text = _post(text)\n",
    "\n",
    "        return text\n",
    "    \n",
    "    if prompt[:2] == '{}':\n",
    "        relation = _refine(prompt[2:])\n",
    "        prompt = subject + ' {}'\n",
    "    else:\n",
    "        temp = prompt.split('{}')\n",
    "        temp[0] = _refine(temp[0])\n",
    "        temp[1] = _refine(temp[1])\n",
    "\n",
    "        if len(temp[0]) < len(temp[1]):\n",
    "            relation = temp[1]\n",
    "            prompt = temp[0] + ' ' + subject + ' {}'\n",
    "            # return None, None\n",
    "        elif len(temp[0]) > len(temp[1]):\n",
    "            relation = temp[0]\n",
    "            prompt = '{} ' + subject + ' ' + temp[1]\n",
    "            # return None, None\n",
    "        else:\n",
    "            if temp[0] == 'What sport does' and temp[1] == 'play? They play':\n",
    "                relation = temp[0]\n",
    "                prompt = '{} ' + subject + ' ' + temp[1]\n",
    "            else:\n",
    "                return None, None\n",
    "    \n",
    "    return prompt, relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "# record_dict = {}\n",
    "\n",
    "# for record in ds:\n",
    "#     case_id = record['case_id']\n",
    "#     prompt, subject, target_new, target_true = (\n",
    "#         record['requested_rewrite'][x] for x in ['prompt', 'subject', 'target_new', 'target_true']\n",
    "#     )\n",
    "\n",
    "#     prompt_with_subject = prompt.format(subject)\n",
    "#     target_new = target_new['str']\n",
    "#     target_true = target_true['str']\n",
    "\n",
    "#     value = {'case_id': case_id, 'prompt': prompt_with_subject, 'target_new': target_new, 'target_true': target_true}\n",
    "\n",
    "#     if not subject in record_dict.keys():\n",
    "#         record_dict[subject] = [value]\n",
    "#     else:\n",
    "#         record_dict[subject].append(value)\n",
    "\n",
    "# with open('./searched_multi_subject.txt', 'w') as f:\n",
    "#     for subject, values in record_dict.items():\n",
    "#         value_len = len(values)\n",
    "#         if value_len > 1:\n",
    "            \n",
    "#             _checked = True\n",
    "#             for idx, value in enumerate(values):\n",
    "#                 case_id, prompt, target_true, target_new = value['case_id'], value['prompt'], value['target_true'], value['target_new']\n",
    "#                 org_texts = f'{prompt} {target_true}'\n",
    "#                 gen_texts = generate(model, tok, [prompt], 1, 100)\n",
    "\n",
    "#                 if not gen_texts.startswith(org_texts):\n",
    "#                     _checked = False\n",
    "#                     break\n",
    "            \n",
    "#             if _checked:\n",
    "#                 f.write(f'### Subject : {subject}, value_len : {value_len}\\n\\n')\n",
    "\n",
    "#                 for idx, value in enumerate(values):\n",
    "#                     case_id, prompt, target_true, target_new = value['case_id'], value['prompt'], value['target_true'], value['target_new']\n",
    "#                     org_texts = f'{prompt} {target_true}'\n",
    "#                     gen_texts = generate(model, tok, [prompt], 1, 100)\n",
    "\n",
    "#                     f.write(f'[{idx}] case_id : {case_id}, prompt : {prompt}\\n')\n",
    "#                     f.write(f'[{idx}] target_true : {target_true}\\n')\n",
    "#                     f.write(f'[{idx}] target_new : {target_new}\\n\\n')\n",
    "#                     f.write(f'[{idx}] org_texts : {org_texts}\\n')\n",
    "#                     f.write(f'[{idx}] gen_texts : {gen_texts}\\n\\n')\n",
    "#                     f.flush()\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "# record_dict = {}\n",
    "\n",
    "# for record in ds:\n",
    "#     subject = record['requested_rewrite']['subject']\n",
    "#     target_new = record['requested_rewrite']['target_new']['str']\n",
    "\n",
    "#     if not subject in record_dict.keys():\n",
    "#         target_new_set = set(target_new)\n",
    "#         record_dict[subject] = [target_new_set, [record]]\n",
    "#     else:\n",
    "#         target_new_set = record_dict[subject][0]\n",
    "#         if not target_new in target_new_set:\n",
    "#             target_new_set.add(target_new)\n",
    "#             records = record_dict[subject][1]\n",
    "#             records.append(record)\n",
    "#             # break\n",
    "\n",
    "# with open('./searched_multi_subject_with_diff_target.txt', 'w') as f:\n",
    "#     records_write = []\n",
    "\n",
    "#     for subject, values in record_dict.items():\n",
    "#         records = values[1]\n",
    "\n",
    "#         if len(records) > 1:\n",
    "#             records_write.extend(records)\n",
    "#     print(f'records_write size : {len(records_write)}')\n",
    "\n",
    "#     f.write(to_json_str(records_write))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "# check_dict = {}\n",
    "\n",
    "# for record in ds:\n",
    "#     case_id = record['case_id']\n",
    "#     prompt, subject, target_new, target_true = (\n",
    "#         record['requested_rewrite'][x] for x in ['prompt', 'subject', 'target_new', 'target_true']\n",
    "#     )\n",
    "\n",
    "#     substrs = _get_all_substrings(prompt)\n",
    "\n",
    "#     for substr in substrs:\n",
    "#         substr = substr.lower()\n",
    "\n",
    "#         _add_dict_freq(check_dict, substr)\n",
    "\n",
    "# sorted_check_dict = sorted_dict(check_dict)\n",
    "\n",
    "# with open('./searched_multi_substrings_from_prompt.txt', 'w') as f:\n",
    "#     for key, value in sorted_check_dict.items():\n",
    "#         key_len = len(key.split())\n",
    "#         f.write(f'{key_len}\\t{key}\\t{value}\\n')\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "# relation_dict = {}\n",
    "# cnt, cnt_relation_front, cnt_relation_mid, cnt_relation_last = 0, 0, 0, 0\n",
    "\n",
    "# for record in ds:\n",
    "#     case_id = record['case_id']\n",
    "#     prompt, subject, target_new, target_true = (\n",
    "#         record['requested_rewrite'][x] for x in ['prompt', 'subject', 'target_new', 'target_true']\n",
    "#     )\n",
    "\n",
    "#     cnt += 1\n",
    "#     if prompt[:2] == '{}':\n",
    "#         cnt_relation_front += 1\n",
    "\n",
    "#         relation = _remove_edge_symbols(prompt[2:])\n",
    "#         relation = _post(relation)\n",
    "\n",
    "#         _add_dict_freq(relation_dict, relation)\n",
    "#     elif prompt[-2:] == '{}':\n",
    "#         cnt_relation_last += 1\n",
    "#     else:\n",
    "#         cnt_relation_mid += 1\n",
    "\n",
    "# print(f'cnt : {cnt}')\n",
    "# print(f'cnt_relation_front : {cnt_relation_front}')\n",
    "# print(f'cnt_relation_mid : {cnt_relation_mid}')\n",
    "# print(f'cnt_relation_last : {cnt_relation_last}')\n",
    "\n",
    "# _write_sorted(relation_dict, './searched_multi_relation_freq.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "# in_file_path = '../data/known_1000.json'\n",
    "# out_file_path = '../data/known_1000_sr_swap.json'\n",
    "\n",
    "# json_dict_list = json_file_to_dict(in_file_path)\n",
    "# write_dict_list = []\n",
    "\n",
    "# for ent in json_dict_list:\n",
    "#     # _print_known(ent)\n",
    "\n",
    "#     prompt = ent['template']\n",
    "#     subject = ent['subject']\n",
    "\n",
    "#     prompt, relation = _swap_sr(prompt, subject)\n",
    "\n",
    "#     if not prompt is None:\n",
    "#         ent['template'] = prompt\n",
    "#         ent['subject'] = relation\n",
    "#         write_dict_list.append(ent)\n",
    "\n",
    "# print(len(write_dict_list))\n",
    "\n",
    "# f = open_file(out_file_path, mode='w')\n",
    "# f.write(to_json_str(write_dict_list))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "ds_name = 'mcf'\n",
    "dataset_size_limit = None\n",
    "ds = load_data(ds_name, tok, dataset_size_limit)\n",
    "\n",
    "write_dict_list = []\n",
    "_check_set = set()\n",
    "\n",
    "for record in ds:\n",
    "    case_id = record['case_id']\n",
    "    prompt = record['requested_rewrite']['prompt']\n",
    "    subject = record['requested_rewrite']['subject']\n",
    "\n",
    "    prompt_swap, relation = _swap_sr(prompt, subject)\n",
    "\n",
    "    if not prompt_swap is None:\n",
    "        record['requested_rewrite']['prompt'] = prompt_swap\n",
    "        record['requested_rewrite']['subject'] = relation\n",
    "        write_dict_list.append(record)\n",
    "    else:\n",
    "        print(f'# error : case_id : {case_id}')\n",
    "        # _check_set.add(prompt)\n",
    "\n",
    "print(len(write_dict_list))\n",
    "# print(_check_set)\n",
    "\n",
    "\n",
    "out_file_path = '../data/multi_counterfact_sr_swap_.json'\n",
    "f = open_file(out_file_path, mode='w')\n",
    "f.write(to_json_str(write_dict_list))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
