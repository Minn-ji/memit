{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, re, copy, random\n",
    "from typing import Tuple, Union, List\n",
    "from itertools import chain\n",
    "from time import time\n",
    "\n",
    "from falcon import falcon_util\n",
    "from util.globals import *\n",
    "from util import nethook\n",
    "\n",
    "from baselines.ft import FTHyperParams, apply_ft_to_model\n",
    "from baselines.mend import MENDHyperParams, MendRewriteExecutor\n",
    "from rome import ROMEHyperParams, apply_rome_to_model\n",
    "from memit import MEMITHyperParams, apply_memit_to_model\n",
    "\n",
    "from experiments.py.eval_utils_counterfact import compute_rewrite_quality_counterfact, test_batch_prediction, test_generation\n",
    "from experiments.py.eval_utils_zsre import compute_rewrite_quality_zsre\n",
    "\n",
    "\n",
    "from dsets import (\n",
    "    AttributeSnippets,\n",
    "    CounterFactDataset,\n",
    "    MENDQADataset,\n",
    "    MultiCounterFactDataset,\n",
    "    get_tfidf_vectorizer\n",
    ")\n",
    "\n",
    "ALG_DICT = {\n",
    "    'FT': (FTHyperParams, apply_ft_to_model),\n",
    "    'MEND': (MENDHyperParams, MendRewriteExecutor().apply_to_model),\n",
    "    'ROME': (ROMEHyperParams, apply_rome_to_model),\n",
    "    'MEMIT': (MEMITHyperParams, apply_memit_to_model)\n",
    "}\n",
    "\n",
    "\n",
    "DS_DICT = {\n",
    "    'mcf': (MultiCounterFactDataset, compute_rewrite_quality_counterfact),\n",
    "    'cf': (CounterFactDataset, compute_rewrite_quality_counterfact),\n",
    "    'zsre': (MENDQADataset, compute_rewrite_quality_zsre),\n",
    "}\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_model(model_name):\n",
    "    if type(model_name) is str:\n",
    "        print('# init_model() Instantiating model')\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "        tok = AutoTokenizer.from_pretrained(model_name)\n",
    "        tok.pad_token = tok.eos_token\n",
    "    else:\n",
    "        model, tok = model_name\n",
    "        model_name = model.config._name_or_path\n",
    "    print(f'\\tmodel : {type(model)}')\n",
    "    print(f'\\ttokenizer : {type(tok)}\\n')\n",
    "\n",
    "    return model, tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(ds_name, tok, dataset_size_limit=None):\n",
    "    ds_class, ds_eval_method = DS_DICT[ds_name]\n",
    "    print(f'# data_load() ds_class : {ds_class}')\n",
    "    print(f'# data_load() ds_eval_method : {ds_eval_method}\\n')\n",
    "    ds = ds_class(DATA_DIR, tok=tok, size=dataset_size_limit)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# init_model() Instantiating model\n",
      "\tmodel : <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "\ttokenizer : <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2-xl'\n",
    "model, tok = _init_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_name = 'mcf'\n",
    "# dataset_size_limit = None\n",
    "# ds = load_data(ds_name, tok, dataset_size_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _generate(model, tok, prompts: List[str], top_k, max_out_len):\n",
    "#     outputs = model.generate(**tok(prompts, return_tensors='pt').to('cuda'),\n",
    "#                              top_k=top_k, max_length=max_out_len,\n",
    "#                              do_sample=False, num_beams=1,\n",
    "#                              pad_token_id=tok.eos_token_id\n",
    "#     )\n",
    "    \n",
    "#     return str(tok.decode(outputs[0], skip_special_token=True)).replace('\\n', '\\t').replace('[\\t]+', '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서부턴 일회성(임시) 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_sorted(out_dict: dict, out_file_path: str):\n",
    "    print(f'_write_sorted() dict : {len(out_dict)} -> {out_file_path}')\n",
    "    \n",
    "    sorted_dict = falcon_util.sorted_dict(out_dict)\n",
    "\n",
    "    with open(out_file_path, 'w') as f:\n",
    "        for key, value in sorted_dict.items():\n",
    "            f.write(f'{key}\\t{value}\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def _random_sampling(datas, n=100, seed=7):\n",
    "    random.seed(seed)\n",
    "    sampled = random.sample(datas, n)\n",
    "    \n",
    "    print(f'_random_sampling() datas : {len(datas)}, sampled : {len(sampled)}')\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rep_do_simple(datas):\n",
    "    ret_datas = []\n",
    "    for data in datas:\n",
    "        case_id = data['case_id']\n",
    "        subject = data['requested_rewrite']['subject']\n",
    "        prompt = data['requested_rewrite']['prompt']\n",
    "        \n",
    "        ret_data = {'case_id': case_id, 'subject': subject, 'prompt': prompt}\n",
    "        ret_datas.append(ret_data)\n",
    "    \n",
    "    return ret_datas\n",
    "\n",
    "\n",
    "def _write_datas(out_file_path, datas, do_simple=False):\n",
    "    if do_simple:\n",
    "        write_datas = _rep_do_simple(datas)\n",
    "    else:\n",
    "        write_datas = datas\n",
    "\n",
    "    print(f'_write_datas() datas : {len(write_datas)} -> {out_file_path}')\n",
    "\n",
    "    falcon_util.make_parent(out_file_path)\n",
    "    f = falcon_util.open_file(out_file_path, mode='w')\n",
    "    f.write(falcon_util.to_json_str(write_datas))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rm_dup_subj(datas, ext_n):\n",
    "    subject_set = set()\n",
    "    rm_dup_subj_datas = []\n",
    "\n",
    "    for data in datas:\n",
    "        subject = data['requested_rewrite']['subject']\n",
    "\n",
    "        if not subject in subject_set:\n",
    "            rm_dup_subj_datas.append(data)\n",
    "            subject_set.add(subject)\n",
    "\n",
    "            if len(rm_dup_subj_datas) == ext_n:\n",
    "                break\n",
    "\n",
    "    print(f'_get_rm_dup_subj() datas : {len(datas)}, rm duplicated subject : {len(rm_dup_subj_datas)}')\n",
    "    return rm_dup_subj_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_subj_rela_dict(datas):\n",
    "    subj_rela_dict = {}\n",
    "\n",
    "    for data in datas:\n",
    "        subject = data['requested_rewrite']['subject']\n",
    "\n",
    "        if not subject in subj_rela_dict.keys():\n",
    "            subj_rela_dict[subject] = [data]\n",
    "        else:\n",
    "            subj_rela_dict[subject].append(data)\n",
    "\n",
    "    print(f'_get_subj_rela_dict() datas : {len(datas)}, subj_rela_dict size : {len(subj_rela_dict)}')\n",
    "    return subj_rela_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dup_subj_lists(datas):\n",
    "    subj_rela_dict = _get_subj_rela_dict(datas)\n",
    "\n",
    "    dup_sizes = {}\n",
    "    for subject in subj_rela_dict.keys():\n",
    "        subject_datas = subj_rela_dict[subject]        \n",
    "        subject_datas_len = len(subject_datas)\n",
    "        falcon_util.add_dict_freq(dup_sizes, subject_datas_len)\n",
    "    print(f'_get_dup_subj_lists() dup_sizes : {dup_sizes}')\n",
    "\n",
    "    dup_subj_datas_lists = [[] for _ in range(len(dup_sizes))]\n",
    "\n",
    "    for subject in subj_rela_dict.keys():\n",
    "        subject_datas = subj_rela_dict[subject]        \n",
    "        subject_datas_len = len(subject_datas)\n",
    "        dup_subj_datas_lists[subject_datas_len-1].extend(subject_datas)\n",
    "    \n",
    "    return dup_subj_datas_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sr_swap(prompt: str, subject: str):\n",
    "    eojs = prompt.split()\n",
    "    \n",
    "    idx = -1\n",
    "    eoj, suf = '#%#', '#%#'\n",
    "\n",
    "    for i, eoj in enumerate(eojs):\n",
    "        idx = i\n",
    "        if eoj == '{}\\'s':\n",
    "            suf = '\\'s'\n",
    "        elif eoj == '{}?':\n",
    "            suf = '?'\n",
    "        elif eoj == '{},':\n",
    "            suf = ','\n",
    "        elif eoj == '{}':\n",
    "            suf = ''\n",
    "        else:\n",
    "            idx = -1\n",
    "        \n",
    "        if idx != -1:\n",
    "            break\n",
    "    # print(f'{idx} : {eoj} : {suf}')\n",
    "\n",
    "    \n",
    "    if idx == -1:\n",
    "        print(f'_sr_swap() prompt error : {prompt}')\n",
    "        return None, None\n",
    "\n",
    "    \n",
    "    if idx == 0:\n",
    "        relation = ' '.join(eojs[1:])\n",
    "        prompt_sr_swap = f'{subject}{suf}' + ' {}'\n",
    "    else:\n",
    "        left = ' '.join(eojs[:idx])\n",
    "        right = ' '.join(eojs[idx+1:])\n",
    "\n",
    "        if 'play?' in right:\n",
    "            relation = right\n",
    "            prompt_sr_swap = f'{left} {subject}{suf}' + ' {}'\n",
    "        elif left == 'The headquarter of' and right == 'is located in':\n",
    "            relation = right\n",
    "            prompt_sr_swap = f'{left} {subject}{suf}' + ' {}'\n",
    "        elif len(left) < len(right):\n",
    "            relation = right\n",
    "            prompt_sr_swap = f'{left} {subject}{suf}' + ' {}'\n",
    "        elif len(left) > len(right):\n",
    "            relation = left\n",
    "            prompt_sr_swap = '{} ' + f'{subject}{suf} {right}'\n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    return prompt_sr_swap, relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prep_set size : 17\n",
      "{'is', 'as', 'to', 'with', 'label', 'for', 'on', 'after', 'at', 'by', 'does', 'from', 'of', 'the', 'an', 'in', 'a'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prep_list = ['in', 'of', 'by', 'from', 'on', 'the', 'is', 'as', 'at', 'for', 'does', 'to', 'a', 'after', 'an', 'with', 'label', ':']\n",
    "prep_list = ['in', 'of', 'by', 'from', 'on', 'the', 'is', 'as', 'at', 'for', 'does', 'to', 'a', 'after', 'an', 'with', 'label', 'with']\n",
    "prep_set = set(prep_list)\n",
    "print(f'prep_set size : {len(prep_set)}\\n{prep_set}\\n')\n",
    "\n",
    "def _check_prep(data: dict, do_print=False):\n",
    "    prompt = data['requested_rewrite']['prompt']\n",
    "    subject = data['requested_rewrite']['subject']\n",
    "\n",
    "    prompt_sr_swap, relation = _sr_swap(prompt, subject)\n",
    "\n",
    "    relation_toks = falcon_util.trim(relation.split(), True)\n",
    "\n",
    "    idx = len(relation_toks)\n",
    "\n",
    "    for i in range(len(relation_toks)-1, -1, -1):\n",
    "        if relation_toks[i] in prep_set:\n",
    "            idx = i\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    relation_rmd_prep = ' '.join(relation_toks[:idx])\n",
    "    \n",
    "    if relation == relation_rmd_prep:\n",
    "        is_rm_prep = False\n",
    "    else:\n",
    "        is_rm_prep = True\n",
    "\n",
    "        if not relation.startswith(relation_rmd_prep):\n",
    "            print(f'# error:\\nrelation : {relation}\\nrelation_rmd_prep : {relation_rmd_prep}')\n",
    "    \n",
    "    rmd_prep = ' '.join(relation_toks[idx:])\n",
    "\n",
    "    if is_rm_prep:\n",
    "        if prompt_sr_swap[:2] == '{}':\n",
    "            prompt_sr_swap_rmd_prep = '{}' + f' {rmd_prep}{prompt_sr_swap[2:]}'\n",
    "        else:\n",
    "            prompt_sr_swap_rmd_prep = f'{prompt_sr_swap} {rmd_prep}'\n",
    "    else:\n",
    "        prompt_sr_swap_rmd_prep = ''\n",
    "\n",
    "    \n",
    "    if do_print:\n",
    "        print(f'prompt : {prompt}')\n",
    "        print(f'subject : {subject}\\n')\n",
    "        print(f'prompt_sr_swap : {prompt_sr_swap}')\n",
    "        print(f'relation : {relation}\\n')\n",
    "        print(f'prompt_sr_swap_rmd_prep : {prompt_sr_swap_rmd_prep}')\n",
    "        print(f'relation_rmd_prep : {relation_rmd_prep}\\n')\n",
    "        print(f'is_rm_prep : {is_rm_prep}, rmd_prep : {rmd_prep}\\n\\n')\n",
    "    \n",
    "    return prompt, subject, prompt_sr_swap, relation, prompt_sr_swap_rmd_prep, relation_rmd_prep, is_rm_prep, rmd_prep\n",
    "\n",
    "\n",
    "# Test\n",
    "# datas = [\n",
    "#     {'requested_rewrite': {'prompt': '{}\\'s originated in', 'subject': 'We Are Wolves'}},\n",
    "#     {'requested_rewrite': {'prompt': 'The native language a of {} is', 'subject': 'Willem Johan Kolff'}},\n",
    "#     {'requested_rewrite': {'prompt': 'In {}, an official language is', 'subject': 'Dutch Language Union'}}\n",
    "# ]\n",
    "\n",
    "# for data in datas:\n",
    "#     _check_prep(data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "\n",
    "def _sr_swap_random(prompt: str, subject: str):\n",
    "    eojs = prompt.split()\n",
    "    eoj_len = len(eojs)\n",
    "\n",
    "    idx_rand = -1\n",
    "    while 1:\n",
    "        idx_rand = random.randint(0, eoj_len-1)\n",
    "        eoj_rand = eojs[idx_rand]\n",
    "\n",
    "        if not '{}' in eoj_rand:\n",
    "            break\n",
    "    \n",
    "    if idx_rand != -1:\n",
    "        relation = eojs[idx_rand]\n",
    "        eojs[idx_rand] = '#%#'\n",
    "        prompt = ' '.join(eojs)\n",
    "        prompt_sr_swap_random = prompt.format(subject)\n",
    "        prompt_sr_swap_random = re.sub('#%#', '{}', prompt_sr_swap_random)\n",
    "\n",
    "        return prompt_sr_swap_random, relation\n",
    "    else:\n",
    "        print(f'_sr_swap_random () error, prompt : {prompt}')\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "# Test\n",
    "# datas = [\n",
    "#     ['{}\\'s in originated in', 'We Are Wolves'],\n",
    "#     ['The native language a of {} is', 'Willem Johan Kolff'],\n",
    "#     ['In {}, an official language is', 'Dutch Language Union']\n",
    "# ]\n",
    "\n",
    "# for data in datas:\n",
    "#     prompt_sr_swap_random, relation = _sr_swap_random(data[0], data[1])\n",
    "    \n",
    "#     print(f'prompt : {data[0]}')\n",
    "#     print(f'subject : {data[1]}\\n')\n",
    "#     print(f'prompt_sr_swap_random : {prompt_sr_swap_random}')\n",
    "#     print(f'relation : {relation}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __sr_swap_idx(prompt: str, subject: str, idx=-1):\n",
    "#     eojs = prompt.split()\n",
    "\n",
    "#     if eojs[idx] == '{}':\n",
    "#         idx -= 1\n",
    "\n",
    "#     relation = eojs[idx]\n",
    "#     eojs[idx] = '#%#'\n",
    "#     prompt = ' '.join(eojs)\n",
    "#     prompt_sr_swap_idx = prompt.format(subject)\n",
    "#     prompt_sr_swap_idx = re.sub('#%#', '{}', prompt_sr_swap_idx)\n",
    "\n",
    "#     return prompt_sr_swap_idx, relation\n",
    "\n",
    "\n",
    "def _sr_swap_idx(prompt: str, subject: str, idx=-1):\n",
    "    eojs = prompt.format(subject).split()\n",
    "    eoj_len = len(eojs)\n",
    "\n",
    "    if 0 <= idx and eoj_len <= idx:\n",
    "        idx = eoj_len-1\n",
    "    elif idx < 0 and (eoj_len + idx) < 0:\n",
    "        idx = 0\n",
    "    \n",
    "    relation = eojs[idx]\n",
    "    eojs[idx] = '{}'\n",
    "    prompt_sr_swap_idx = ' '.join(eojs)\n",
    "    return prompt_sr_swap_idx, relation\n",
    "\n",
    "\n",
    "# Test\n",
    "# datas = [\n",
    "#     ['{}\\'s in originated in', 'We Are Wolves'],\n",
    "#     ['The native language a of {} is', 'Willem Johan Kolff'],\n",
    "#     ['In {}, an official language is', 'Dutch Language Union']\n",
    "# ]\n",
    "\n",
    "# for data in datas:\n",
    "#     prompt_sr_swap_idx, relation = _sr_swap_idx(data[0], data[1], -2)\n",
    "    \n",
    "#     print(f'prompt : {data[0]}')\n",
    "#     print(f'subject : {data[1]}\\n')\n",
    "#     print(f'prompt_sr_swap_idx : {prompt_sr_swap_idx}')\n",
    "#     print(f'relation : {relation}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_data(data: dict, do_sr_swap=False):\n",
    "    case_id = data['case_id']\n",
    "    data_rq = data['requested_rewrite']\n",
    "\n",
    "    subject = data_rq['subject']\n",
    "    prompt = data_rq['prompt']\n",
    "\n",
    "    print(f'\\ncase_id : {case_id}')\n",
    "    if 'org_prompt' in data_rq.keys():\n",
    "        print(f'org_prompt : {data_rq[\"org_prompt\"]}')\n",
    "    if 'org_subject' in data_rq.keys():\n",
    "        print(f'org_subject : {data_rq[\"org_subject\"]}')\n",
    "\n",
    "    print(f'\\nprompt : {prompt}')\n",
    "    print(f'subject : {subject}\\n')\n",
    "\n",
    "    if do_sr_swap:\n",
    "        prompt_sr_swap, relation = _sr_swap(prompt, subject)\n",
    "\n",
    "        relation_toks = falcon_util.trim(relation.split(), True)\n",
    "        relation_last_tok = relation_toks[-1]\n",
    "\n",
    "        print(f'prompt_sr_swap : {prompt_sr_swap}')\n",
    "        print(f'relation : {relation}')\n",
    "        print(f'relation_last_tok : {relation_last_tok}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _print_known(ent: dict):\n",
    "#     known_id = ent['known_id']\n",
    "#     subject = ent['subject']\n",
    "#     attribute = ent['attribute']\n",
    "#     template = ent['template']\n",
    "#     prediction = ent['prediction']\n",
    "#     prompt = ent['prompt']\n",
    "#     relation_id = ent['relation_id']\n",
    "\n",
    "#     print(f'known_id : {known_id}')\n",
    "#     print(f'subject : {subject}')\n",
    "#     print(f'attribute : {attribute}')\n",
    "#     print(f'template : {template}')\n",
    "#     print(f'prediction : {prediction}')\n",
    "#     print(f'prompt : {prompt}')\n",
    "#     print(f'relation_id : {relation_id}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서부턴 실제 실행 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아무것도 실행되지 않았음\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 실행 코드\n",
    "###############################################################################\n",
    "\n",
    "do_run, do_simple = False, False\n",
    "\n",
    "if do_run:\n",
    "    out_dir = './data/hclt'\n",
    "\n",
    "    rand_n = 10000\n",
    "    ext_n = 300\n",
    "\n",
    "    # data load\n",
    "    ds_name = 'mcf'\n",
    "    dataset_size_limit = None\n",
    "    datas = _load_data(ds_name, tok, dataset_size_limit)\n",
    "\n",
    "    # random n 추출\n",
    "    sampled = _random_sampling(datas.data, rand_n)\n",
    "\n",
    "    # subject가 중복되지 않은 데이터만 선별\n",
    "    rm_dup_subj_datas = _rm_dup_subj(sampled, ext_n)\n",
    "\n",
    "    out_file_path = f'{out_dir}/hclt_multi_counterfact_rand_uniq_subj_{ext_n}.json'\n",
    "    _write_datas(out_file_path, rm_dup_subj_datas, do_simple)\n",
    "\n",
    "    # subject가 중복된 데이터만을 선별\n",
    "    dup_subj_datas_lists = _get_dup_subj_lists(datas)\n",
    "\n",
    "    for i, dup_subj_datas_list in enumerate(dup_subj_datas_lists):\n",
    "        out_file_path = f'{out_dir}/hclt_multi_counterfact_dup_subj_n{i+1}.json'\n",
    "        _write_datas(out_file_path, dup_subj_datas_list, do_simple)\n",
    "\n",
    "    # subject가 중복되지 않은 데이터와 중복된 데이터의 비율을 변경하면서 실험 데이터 생성\n",
    "    total_len = len(rm_dup_subj_datas)\n",
    "    step = 10\n",
    "    step_len = int(total_len / step)\n",
    "\n",
    "    for i in range(0, step+1):\n",
    "        idx = i * step_len\n",
    "\n",
    "        if idx == 0:\n",
    "            datas_1 = rm_dup_subj_datas\n",
    "\n",
    "        else:\n",
    "            datas_1 = rm_dup_subj_datas[:-(i*step_len)]\n",
    "        datas_2 = dup_subj_datas_list[1][:(i*step_len)]\n",
    "        \n",
    "        write_datas = []\n",
    "        write_datas.extend(datas_1)\n",
    "        write_datas.extend(datas_2)\n",
    "\n",
    "        out_file_path = f'{out_dir}/hclt_multi_counterfact_experiment1_{(step-i)}-{i}.json'\n",
    "        _write_datas(out_file_path, write_datas, do_simple)\n",
    "\n",
    "    # subject가 중복된 데이터를 기준으로 하나의 batch 에서는 중복이 없고, batch 단위로는 중복되도록 실험 데이터 생성\n",
    "    batch_size = 3\n",
    "    batch_dup_subj_datas_list = [[] for _ in range(batch_size)]\n",
    "    batch_dup_subj_datas_all = []\n",
    "\n",
    "    for i, data in enumerate(dup_subj_datas_list[batch_size-1]):\n",
    "        batch_dup_subj_datas_list[i%batch_size].append(data)\n",
    "\n",
    "    for i, batch_dup_subj_datas in enumerate(batch_dup_subj_datas_list):\n",
    "        out_file_path = f'{out_dir}/hclt_multi_counterfact_experiment2_batch{i+1}.json'\n",
    "        _write_datas(out_file_path, batch_dup_subj_datas, do_simple)\n",
    "\n",
    "        batch_dup_subj_datas_all.extend(batch_dup_subj_datas)\n",
    "\n",
    "    out_file_path = f'{out_dir}/hclt_multi_counterfact_experiment2_batch_all.json'\n",
    "    # batch_dup_subj_datas_all.reverse()\n",
    "    _write_datas(out_file_path, batch_dup_subj_datas_all, do_simple)\n",
    "else:\n",
    "    print('아무것도 실행되지 않았음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아무것도 실행되지 않았음\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 실행 코드 : prompt에서 기호가 포함된 경우 확인, _sr_swap() 테스트\n",
    "###############################################################################\n",
    "\n",
    "do_run = False\n",
    "\n",
    "if do_run:\n",
    "    out_dir = './data'\n",
    "\n",
    "    ds_name = 'mcf'\n",
    "    datas = _load_data(ds_name, tok)\n",
    "\n",
    "\n",
    "    prompt_in_symbol_freq_dict = dict()\n",
    "\n",
    "    for data in datas:\n",
    "        data_rq = data['requested_rewrite']\n",
    "        prompt_org = data_rq['prompt']\n",
    "        prompt = prompt_org\n",
    "\n",
    "        # prompt = re.sub('{},', ' ', prompt)         # {},\n",
    "        # prompt = re.sub('{}\\\\?', ' ', prompt)       # {}?\n",
    "        # prompt = re.sub('{}\\\\\\'s', ' ', prompt)     # {}'s\n",
    "        # prompt = re.sub('{}', ' ', prompt)\n",
    "\n",
    "        if falcon_util.contains_symbol(prompt):\n",
    "            falcon_util.add_dict_freq(prompt_in_symbol_freq_dict, prompt_org)\n",
    "        else:\n",
    "            print(f'### error 지금은 여기 걸리면 안됨 : {prompt_org}')\n",
    "\n",
    "    print(f'prompt_in_symbol_freq_dict size : {len(prompt_in_symbol_freq_dict)}')\n",
    "\n",
    "    out_file_path = f'{out_dir}/multi_counterfact_prompt_freq.txt'\n",
    "    _write_sorted(prompt_in_symbol_freq_dict, out_file_path)\n",
    "\n",
    "    \n",
    "    # subject-relation swap 잘 되는지 확인\n",
    "    out_file_path = f'{out_dir}/multi_counterfact_prompt_sr_swap_check.txt'\n",
    "    out_file = falcon_util.open_file(out_file_path, mode='w')\n",
    "\n",
    "    subject = '#%#'\n",
    "    for prompt in prompt_in_symbol_freq_dict.keys():\n",
    "        prompt_sr_swap, relation = _sr_swap(prompt, subject)\n",
    "        relation_rm_symbol_edge = falcon_util.remove_symbol_edge(relation)\n",
    "        _a = prompt.format(subject)\n",
    "        _b = prompt_sr_swap.format(relation)\n",
    "\n",
    "        ''' text 파일 검토용 '''\n",
    "        # out_file.write(f'prompt : {prompt}\\n')\n",
    "        # out_file.write(f'subject : {subject}\\n\\n')\n",
    "        # out_file.write(f'prompt_sr_swap : {prompt}\\n')\n",
    "        # out_file.write(f'relation : {relation}\\n\\n')\n",
    "        # if _a == _b:\n",
    "        #     out_file.write(f'# subject-relation swap check passed\\n\\n')\n",
    "        # else:\n",
    "        #     out_file.write(f'# error\\n_a : {_a}\\n_b : {_b}\\n\\n')\n",
    "        \n",
    "        ''' excel 파일 검토용 '''\n",
    "        out_line = f'{prompt}\\t{subject}\\t{prompt_sr_swap}\\t{relation}'\n",
    "        out_line += f'\\t{relation_rm_symbol_edge}\\t{relation==relation_rm_symbol_edge}'\n",
    "        out_line += f'\\t{_a}\\t{_b}\\t{_a == _b}\\n'\n",
    "        out_file.write(out_line)\n",
    "\n",
    "    \n",
    "    out_file.close()\n",
    "else:\n",
    "    print('아무것도 실행되지 않았음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data_load() ds_class : <class 'dsets.counterfact.MultiCounterFactDataset'>\n",
      "# data_load() ds_eval_method : <function compute_rewrite_quality_counterfact at 0x7f0610955700>\n",
      "\n",
      "Loaded dataset with 20877 elements\n",
      "\n",
      "_get_subj_rela_dict() datas : 20877, subj_rela_dict size : 20099\n",
      "_get_dup_subj_lists() dup_sizes : {1: 19366, 2: 693, 3: 35, 4: 5}\n",
      "\n",
      "data_uniq_subj_list size : 19366\n",
      "\n",
      "datas_rmd_f size : 2655\n",
      "datas_rmd_t size : 16711\n",
      "\n",
      "_random_sampling() datas : 2655, sampled : 1000\n",
      "_random_sampling() datas : 16711, sampled : 1000\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_f_rand_1000.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_rmd_prep.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_random.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_idx_0.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_idx_1.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_idx_2.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_idx_-3.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_idx_-2.json\n",
      "_write_datas() datas : 1000 -> ./data/test_sets/multi_counterfact_uniq_subj_rmd_t_rand_1000_sr_swap_idx_-1.json\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 실행 코드 : relation을 subject로 봤을 때의 모델 편집 성능 비교를 위한 데이터셋 구축\n",
    "###############################################################################\n",
    "\n",
    "do_run, do_print = True, False\n",
    "\n",
    "if do_run:\n",
    "    out_dir = './data/test_sets'\n",
    "    rand_n = 1000\n",
    "    \n",
    "    ds_name = 'mcf'\n",
    "    datas = _load_data(ds_name, tok)\n",
    "\n",
    "    # subject를 key 값으로 묶고, 하나의 subject가 가지는 relation의 수 별로 다시 묶음\n",
    "    data_dup_subj_lists = _get_dup_subj_lists(datas)\n",
    "\n",
    "    # 하나의 subject가 단일 relation을 갖는 데이터\n",
    "    data_uniq_subj_list = data_dup_subj_lists[0]\n",
    "    print(f'\\ndata_uniq_subj_list size : {len(data_uniq_subj_list)}\\n')\n",
    "\n",
    "\n",
    "    '''\n",
    "        전치사의 제거 여부를 미리 확인\n",
    "            - datas_rmd_f : prompt의 relation 부분에서 전치사가 제거되지 않는 경우 (speaks the language)\n",
    "            - datas_rmd_t : prompt의 relation 부분에서 전치사가 제거되는 경우 (an official language \"is\")\n",
    "    '''\n",
    "    datas_rmd_f, datas_rmd_t = [], []\n",
    "    for data in data_uniq_subj_list:\n",
    "        prompt, subject, prompt_sr_swap, relation, prompt_sr_swap_rmd_prep, relation_rmd_prep, is_rm_prep, rmd_prep = _check_prep(data)\n",
    "        # data['requested_rewrite']['org_prompt'] = prompt\n",
    "        # data['requested_rewrite']['org_subject'] = subject\n",
    "        # data['requested_rewrite']['prompt'] = prompt_sr_swap\n",
    "        # data['requested_rewrite']['subject'] = relation_rmd_prep\n",
    "\n",
    "        if not is_rm_prep:\n",
    "            datas_rmd_f.append(data)\n",
    "        else:\n",
    "            datas_rmd_t.append(data)\n",
    "    print(f'datas_rmd_f size : {len(datas_rmd_f)}')\n",
    "    print(f'datas_rmd_t size : {len(datas_rmd_t)}\\n')\n",
    "\n",
    "    datas_rmd_f_rand = _random_sampling(datas_rmd_f, rand_n)\n",
    "    datas_rmd_t_rand = _random_sampling(datas_rmd_t, rand_n)\n",
    "    out_file_path = f'{out_dir}/multi_counterfact_uniq_subj_rmd_f_rand_{rand_n}.json'\n",
    "    _write_datas(out_file_path, datas_rmd_f_rand)\n",
    "    out_file_path = f'{out_dir}/multi_counterfact_uniq_subj_rmd_t_rand_{rand_n}.json'\n",
    "    _write_datas(out_file_path, datas_rmd_t_rand)\n",
    "\n",
    "    \n",
    "    '''\n",
    "        datas_rmd_t : prompt의 relation 부분에서 전치사가 제거되는 경우 (an official language \"is\")\n",
    "            - 위 경우에 대하여, 실제 데이터에서 subject와 relation의 value를 swap\n",
    "\n",
    "            - relation에 대해서 편집을 수행하기 위함\n",
    "                - subject를 제외한 나머지 부분을 relation으로 사용해서 편집한 경우 (*_sr_swap.json)\n",
    "                - subject를 제외한 나머지 부분을 relation으로 사용하되, 전치사 부분을 제거하고 편집한 경우 (*_sr_swap_rmd_prep.json)\n",
    "    '''\n",
    "    datas_rmd_t_rand_sr_swap = []\n",
    "    datas_rmd_t_rand_sr_swap_rmd_prep = []\n",
    "    datas_rmd_t_rand_sr_swap_random = []\n",
    "    \n",
    "    for data in datas_rmd_t_rand:\n",
    "        prompt, subject, prompt_sr_swap, relation, prompt_sr_swap_rmd_prep, relation_rmd_prep, is_rm_prep, rmd_prep = _check_prep(data)\n",
    "\n",
    "        data_1 = copy.deepcopy(data)\n",
    "        data_1['requested_rewrite']['prompt'] = prompt_sr_swap\n",
    "        data_1['requested_rewrite']['subject'] = relation\n",
    "        datas_rmd_t_rand_sr_swap.append(data_1)\n",
    "\n",
    "        data_2 = copy.deepcopy(data)\n",
    "        data_2['requested_rewrite']['prompt'] = prompt_sr_swap_rmd_prep\n",
    "        data_2['requested_rewrite']['subject'] = relation_rmd_prep\n",
    "        datas_rmd_t_rand_sr_swap_rmd_prep.append(data_2)\n",
    "\n",
    "        prompt_sr_swap_random, relation_random = _sr_swap_random(prompt, subject)\n",
    "        data_3 = copy.deepcopy(data)\n",
    "        data_3['requested_rewrite']['prompt'] = prompt_sr_swap_random\n",
    "        data_3['requested_rewrite']['subject'] = relation_random\n",
    "        datas_rmd_t_rand_sr_swap_random.append(data_3)\n",
    "\n",
    "    out_file_path = f'{out_dir}/multi_counterfact_uniq_subj_rmd_t_rand_{rand_n}_sr_swap.json'\n",
    "    _write_datas(out_file_path, datas_rmd_t_rand_sr_swap)\n",
    "\n",
    "    out_file_path = f'{out_dir}/multi_counterfact_uniq_subj_rmd_t_rand_{rand_n}_sr_swap_rmd_prep.json'\n",
    "    _write_datas(out_file_path, datas_rmd_t_rand_sr_swap_rmd_prep)\n",
    "\n",
    "    out_file_path = f'{out_dir}/multi_counterfact_uniq_subj_rmd_t_rand_{rand_n}_sr_swap_random.json'\n",
    "    _write_datas(out_file_path, datas_rmd_t_rand_sr_swap_random)\n",
    "\n",
    "    '''\n",
    "        무조건 마지막 토큰, 또는 마지막 이전 토큰 등의 단순한 토큰 index로 편집 대상 토큰 설정\n",
    "    '''\n",
    "    idxs = [0, 1, 2, -3, -2, -1]\n",
    "    for idx in idxs:\n",
    "\n",
    "        datas_rmd_t_rand_sr_swap_idx = []\n",
    "        for data in datas_rmd_t_rand:\n",
    "            prompt = data['requested_rewrite']['prompt']\n",
    "            subject = data['requested_rewrite']['subject']\n",
    "\n",
    "            prompt_sr_swap_idx, relation_idx = _sr_swap_idx(prompt, subject, idx)\n",
    "\n",
    "            data_1 = copy.deepcopy(data)\n",
    "            data_1['requested_rewrite']['prompt'] = prompt_sr_swap_idx\n",
    "            data_1['requested_rewrite']['subject'] = relation_idx\n",
    "            datas_rmd_t_rand_sr_swap_idx.append(data_1)\n",
    "        \n",
    "        out_file_path = f'{out_dir}/multi_counterfact_uniq_subj_rmd_t_rand_{rand_n}_sr_swap_idx_{str(idx)}.json'\n",
    "        _write_datas(out_file_path, datas_rmd_t_rand_sr_swap_idx)\n",
    "\n",
    "else:    \n",
    "    print('아무것도 실행되지 않았음')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
